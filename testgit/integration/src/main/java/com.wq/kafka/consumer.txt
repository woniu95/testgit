		Properties props = new Properties();
		// kafka 集群地址设置
		props.put("bootstrap.servers", kafkaConfiguration.getFullIp());
		// 订阅topic的用户组设置
		// props.put("group.id", this.groupId);
		props.put("group.id", "local_sync");
		props.put("max.poll.records", "10");		
		// 复位OFFSET, 断线重连时需用
		props.put("auto.offset.reset", "earliest");	
		// 自动提交设置
		props.put("enable.auto.commit", "false");
		// 自动提交 offset 间隔时间
		props.put("auto.commit.interval.ms", "3000");
		props.put("heartbeat.interval.ms", "9000");
		// session 连接超时时间
//		props.put("session.timeout.ms",  30 * 1000);
		props.put("fetch.max.wait.ms", 5 * 1000);
//		props.put("request.timeout.ms",   35 * 1000);	
		// 最大大小为2M
		props.put("max.partition.fetch.bytes", 2*1024*1024);
		// key&value 反序列化设置
		props.put("key.deserializer", kafkaConfiguration.getKeyDeserializer());
		props.put("value.deserializer", kafkaConfiguration.getValueDeserializer());
		
		//消费
		KafkaConsumer consumer = new KafkaConsumer<String, String>(props);
		//		consumer.subscribe(Arrays.asList(topic));
		consumer.assign( Arrays.asList(new TopicPartition(topic, 0)));

		ConsumerRecords<String, String> rs = consumer.poll(maxFetchDataTime);
        for (TopicPartition partition : rs.partitions()) {
            List<ConsumerRecord<String, String>> partitionRecords = rs.records(partition);
            for (ConsumerRecord<String, String> record : partitionRecords) {
                // do logic
                logger.info("receive kafka message offset: " + record.offset());
                
                //jmsMessageListener.receiveMsg(record.value());

            }
        }

        consumer.commitAsync();